{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-K Filings: Data Extraction\n",
    "\n",
    "This notebook demonstrates how to download 10-K filings from the SEC EDGAR database using the 10-K Analysis Toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add project root to path for importing local modules\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import the SECDataLoader class\n",
    "from src.data.data_loader import SECDataLoader\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Data Loader\n",
    "\n",
    "First, we'll create an instance of the `SECDataLoader` class, which we'll use to download 10-K filings from the SEC EDGAR database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "if not os.path.exists('../data/cache'):\n",
    "    os.makedirs('../data/cache')\n",
    "if not os.path.exists('../data/raw'):\n",
    "    os.makedirs('../data/raw')\n",
    "\n",
    "# Initialize the data loader\n",
    "loader = SECDataLoader(cache_dir='../data/cache')\n",
    "print(f\"Data loader initialized with cache directory: {loader.cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Companies and Time Period\n",
    "\n",
    "Now, let's define the list of companies (by ticker symbol) and the years for which we want to download 10-K filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of ticker symbols\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "\n",
    "# Define years to download\n",
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "print(f\"Companies: {', '.join(tickers)}\")\n",
    "print(f\"Years: {', '.join(map(str, years))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Up CIK Numbers\n",
    "\n",
    "The SEC identifies companies by their Central Index Key (CIK). Let's look up the CIK numbers for our target companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up CIK numbers for each ticker\n",
    "cik_mapping = {}\n",
    "\n",
    "for ticker in tqdm(tickers, desc=\"Looking up CIK numbers\"):\n",
    "    cik = loader.get_cik_for_ticker(ticker)\n",
    "    cik_mapping[ticker] = cik\n",
    "    \n",
    "# Display the results\n",
    "cik_df = pd.DataFrame(list(cik_mapping.items()), columns=['Ticker', 'CIK'])\n",
    "cik_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 10-K Filings\n",
    "\n",
    "Now, let's download the 10-K filings for our target companies and years. This may take some time, as we need to make multiple requests to the SEC EDGAR database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download filings\n",
    "print(f\"Downloading 10-K filings for {len(tickers)} companies over {len(years)} years...\")\n",
    "print(\"This may take several minutes depending on the number of filings.\")\n",
    "\n",
    "filings_df = loader.load_filings(tickers, years=years)\n",
    "\n",
    "print(f\"Downloaded {len(filings_df)} filings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Downloaded Data\n",
    "\n",
    "Let's take a look at the downloaded filings to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic information\n",
    "print(f\"Downloaded {len(filings_df)} filings for {filings_df['ticker'].nunique()} companies.\")\n",
    "print(f\"Years covered: {sorted(filings_df['filing_year'].unique())}\")\n",
    "print(\"\\nColumns in the DataFrame:\")\n",
    "print(filings_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows (excluding HTML content for brevity)\n",
    "display_cols = [col for col in filings_df.columns if col != 'filing_html']\n",
    "filings_df[display_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Coverage\n",
    "\n",
    "Let's check the coverage of our downloaded data to see if we have filings for all companies and years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table to check coverage\n",
    "coverage = pd.pivot_table(\n",
    "    filings_df,\n",
    "    values='accession_number',\n",
    "    index='ticker',\n",
    "    columns='filing_year',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Filing Dates\n",
    "\n",
    "Let's visualize when the filings were submitted to the SEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert filing_date to datetime if needed\n",
    "if not pd.api.types.is_datetime64_dtype(filings_df['filing_date']):\n",
    "    filings_df['filing_date'] = pd.to_datetime(filings_df['filing_date'])\n",
    "\n",
    "# Plot filing dates\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Get unique companies\n",
    "companies = filings_df['ticker'].unique()\n",
    "\n",
    "# Plot a line for each company\n",
    "for i, company in enumerate(companies):\n",
    "    company_filings = filings_df[filings_df['ticker'] == company]\n",
    "    plt.scatter(\n",
    "        company_filings['filing_date'],\n",
    "        [i] * len(company_filings),\n",
    "        label=company,\n",
    "        s=100\n",
    "    )\n",
    "\n",
    "# Set y-ticks to company names\n",
    "plt.yticks(range(len(companies)), companies)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Filing Date', fontsize=14)\n",
    "plt.title('10-K Filing Dates by Company', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Format x-axis with years\n",
    "import matplotlib.dates as mdates\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check File Sizes\n",
    "\n",
    "Let's check the sizes of the downloaded filings to get an idea of how much data we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate HTML content size\n",
    "filings_df['html_size_kb'] = filings_df['filing_html'].apply(lambda x: len(x) / 1024 if isinstance(x, str) else 0)\n",
    "\n",
    "# Plot file sizes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='ticker', y='html_size_kb', data=filings_df)\n",
    "plt.title('10-K Filing Sizes by Company', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Company', fontsize=14)\n",
    "plt.ylabel('File Size (KB)', fontsize=14)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample HTML Content\n",
    "\n",
    "Let's take a quick look at a sample of the HTML content to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample filing\n",
    "sample_filing = filings_df.iloc[0]\n",
    "print(f\"Sample filing: {sample_filing['ticker']} from {sample_filing['filing_date']}\")\n",
    "\n",
    "# Show first 1000 characters of HTML\n",
    "html_preview = sample_filing['filing_html'][:1000] if isinstance(sample_filing['filing_html'], str) else ''\n",
    "print(f\"\\nHTML preview (first 1000 characters):\\n{html_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Downloaded Data\n",
    "\n",
    "Now that we have downloaded and explored the data, let's save it to disk for use in later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle file\n",
    "output_file = '../data/raw/10k_filings.pkl'\n",
    "filings_df.to_pickle(output_file)\n",
    "print(f\"Saved {len(filings_df)} filings to {output_file}\")\n",
    "\n",
    "# Save metadata only (without HTML content) to CSV for easy inspection\n",
    "metadata_file = '../data/raw/10k_filings_metadata.csv'\n",
    "filings_df[display_cols].to_csv(metadata_file, index=False)\n",
    "print(f\"Saved metadata to {metadata_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In the next notebook (`2_data_preprocessing.ipynb`), we'll preprocess the downloaded filings by:\n",
    "1. Extracting individual sections (e.g., Risk Factors, MD&A, Financial Statements)\n",
    "2. Cleaning the text for analysis\n",
    "3. Extracting tables for financial data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}